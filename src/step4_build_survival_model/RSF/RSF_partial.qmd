---
title: 'Build Survival Model: Random Survival Forest'
author: 'Mingcheng Hu'
params:
    adjust_type:
        label: 'Adjustment Type of Survival Model'
        value: 'partial'
        choices:
            - 'minimal'
            - 'partial'
            - 'full'
    impute_type:
        label: 'Imputation Type'
        value: 'unimputed'
        choices:
            - 'unimputed'
            - 'imputed'
    include_statin:
        label: 'Include Participants Taking Statin in the Model'
        value: 'no'
        choices:
            - 'yes'
            - 'no'
format: 
    pdf:
        toc: true
        keep-tex: true
        include-in-header: 
            text: |
                \usepackage{fvextra}
                \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
                \DefineVerbatimEnvironment{OutputCode}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r output = FALSE}
library(tidyverse)
library(survival)
library(randomForestSRC)
library(caret)
library(survcomp)
library(parallel)
library(doParallel)
library(mcprogress) # wrap mclapply with progress bar.
library(kableExtra) # include knitr automatically

source("/work/users/y/u/yuukias/BIOS-Material/BIOS992/utils/csv_utils.r")
# * Don't use setwd() for Quarto documents!
# setwd("/work/users/y/u/yuukias/BIOS-Material/BIOS992/data")

adjust_type <- ifelse(exists("params"), params$adjust_type, "partial") # options: "minimal", "partial", "full"
impute_type <- ifelse(exists("params"), params$impute_type, "unimputed") # options: "unimputed", "imputed"
include_statin <- ifelse(exists("params"), params$include_statin, "no") # options: "yes", "no"

n_folds <- 10
set.seed(1234)
```

```{r}
# string of parameters
adjust_type_str <- switch(adjust_type,
    minimal = "minimal",
    partial = "partial",
    full = "full"
)
print(paste0("Model Adjustment Type: ", adjust_type_str))
impute_type_str <- switch(impute_type,
    unimputed = "unimputed",
    imputed = "imputed"
)
print(paste0("Data Imputation Type: ", impute_type_str))
```

# Load Data

```{r}
if (include_statin == "yes") {
    data_train <- read.csv(paste0("/work/users/y/u/yuukias/BIOS-Material/BIOS992/data/train_data_", impute_type_str, "_statin.csv"),
        header = TRUE
    )
} else {
    data_train <- read.csv(paste0("/work/users/y/u/yuukias/BIOS-Material/BIOS992/data/train_data_", impute_type_str, ".csv"),
        header = TRUE
    )
}

data_train <- data_train[, -1] # the first column is the index generated by sklearn
(dim(data_train))
```

```{r}
data <- select_subset(data_train, type = adjust_type)
(dim(data))
```

```{r}
colnames(data)
```

```{r}
data <- tibble::as_tibble(data)
```

```{r}
# * It is very hard to compare the HR as different predictors are on different magnitudes, so we need to normalize them.
time_col <- data$time
event_col <- data$event
data <- data %>%
    select(-c(time, event)) %>%
    mutate(across(where(is.numeric), scale)) %>%
    mutate(
        time = time_col,
        event = event_col
    )
```

**Note now the interpretation of HR is different! For example, if HR=1.16 for the predictor in the univariate model fitted using scaled data, it means that each standard deviation increase is associated with 16% higher risk of event.**

```{r}
# For RSF model, we don't need to exclude the missing values
```

# Random Survival Forest (RSF)

## Variable Selection

The `method` argument can be set to `vh` instead for variable hunting, which should be used for problems where the number of variables is substantially larger than the sample size.

```{r label = "Variable Selection"}
n_cores <- min(parallel::detectCores() - 1, 32)
cl <- makeCluster(n_cores)
registerDoParallel(cl)

rsf_var_select <- var.select.rfsrc(Surv(time, event) ~ .,
    data = data,
    method = "md",
    seed = 1234,
    ntree = 200,
    parallel = TRUE
) # minimal depth variable selection

stopCluster(cl)
```

```{r echo = FALSE}
save(rsf_var_select,
    file = get_data_path("rsf_var_select_model", adjust_type_str, impute_type_str, include_statin, model = "rsf")
)
```

```{r echo = FALSE}
load(get_data_path("rsf_var_select_model", adjust_type_str, impute_type_str, include_statin, model = "rsf"))
```

```{r}
vars_ranked <- rsf_var_select$topvars
```

## Cross Validation to Select the Best Number of Features

We will use 10-fold cross validation to select the best number of features used in the model.

```{r label = "Cross Validation to Select the Best Number of Features"}
set.seed(1234)
folds <- createFolds(data$event, k = n_folds) # return indices of folds

cv_errors <- pmclapply(seq(1, length(vars_ranked), by = 1), function(num_vars) {
    selected_vars <- vars_ranked[1:num_vars]

    fold_errors <- sapply(folds, function(fold_idx) {
        train_data_fold <- data[-fold_idx, c("time", "event", selected_vars)]
        val_data_fold <- data[fold_idx, c("time", "event", selected_vars)]
        model <- rfsrc.fast(Surv(time, event) ~ .,
            data = train_data_fold,
            ntree = 200,
            forest = TRUE
        )
        pred <- predict(model,
            newdata = val_data_fold,
            na.action = "na.impute"  # * There may be missing values in the dataset
        )$predicted  # define pred has attributes survival(sample_size*time) and predicted(sample_size) for risk
        # Use C-index to measure the performance of the model
        1 - concordance.index(
            pred,  # pass risk prediction for first argument
            val_data_fold$time, 
            val_data_fold$event
        )$c.index
    })
    mean(fold_errors)
}, title = "Cross Validation to Select the Best Number of Features")
```

```{r include = FALSE}
best_num_vars <- which.min(cv_errors)
vars_selected <- vars_ranked[1:best_num_vars]
```

```{r echo = FALSE}
save(cv_errors, vars_selected,
    file = get_data_path("rsf_var_select_name", adjust_type_str, impute_type_str, include_statin, model = "rsf")
)
```

```{r echo = FALSE}
load(get_data_path("rsf_var_select_name", adjust_type_str, impute_type_str, include_statin, model = "rsf"))
```

```{r}
cv_errors <- as.numeric(cv_errors)
plot(1:length(cv_errors), cv_errors)
best_num_vars <- which.min(cv_errors)
vars_selected <- vars_ranked[1:best_num_vars]
```

```{r}
print(paste0("The best number of features to retain is ", best_num_vars))
```

## Model Fitting

```{r label = "Model Fitting"}
data_selected <- data[, c("time", "event", vars_selected)]

# Before formally fitting the model, we can tune the hyperparameters to find:
# 1. optimal mtry (possible split at each node)
# 2. optimal nodesize (minimum size of terminal nodes)
rsf_tuned <- tune.rfsrc(
    Surv(time, event) ~ .,
    data = data_selected,
)

rsf_model <- rfsrc(Surv(time, event) ~ .,
    data = data_selected,
    ntree = 500,
    mtry = rsf_tuned$best.mtry,
    nodesize = rsf_tuned$best.nodesize
)
```

```{r}
# We also fit the full model
rsf_tuned_full <- tune.rfsrc(
    Surv(time, event) ~ .,
    data = data,
)

rsf_model_full <- rfsrc(Surv(time, event) ~ .,
    data = data,
    ntree = 1000,
    mtry = rsf_tuned_full$best.mtry,
    nodesize = rsf_tuned_full$best.nodesize
)
```

```{r echo = FALSE}
save(rsf_model, rsf_model_full,
    file = get_data_path("rsf_model", adjust_type_str, impute_type_str, include_statin, model = "rsf")
)
```

```{r echo = FALSE}
load(get_data_path("rsf_model", adjust_type_str, impute_type_str, include_statin, model = "rsf"))
```
