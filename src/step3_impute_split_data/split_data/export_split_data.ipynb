{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we formally export **all data** that should be used for survival analysis and split them for survival analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from utils.constants import DatabaseConfig, TableNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DatabaseConfig.DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "primary_key = 'eid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data\n",
    "\n",
    "Here we export data to data frames rather than to csv files. They will be split later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of retreiving all data using a large query, we will retreive data for each table separately and then merge them.\n",
    "\n",
    "# * This exclusion criteria may be modified for sensitivity analysis.\n",
    "exclusion_criteria = \"WHERE s.statins = 0 AND s.ecg_hrv_ok = 1 AND s.ecg_before_cvd == 0\"\n",
    "\n",
    "\n",
    "def retrieve_data(cursor, table_name, primary_key=primary_key, exclusion_criteria=exclusion_criteria):\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    columns = [row[1] for row in cursor.fetchall()]\n",
    "    columns = [col for col in columns if col != primary_key]\n",
    "    query_sql = f\"\"\"\n",
    "    SELECT t.{primary_key}, {', '.join(f't.{col}' for col in columns)} \n",
    "    FROM {table_name} t INNER JOIN {TableNames.STATUS} s ON t.eid = s.eid\n",
    "    {exclusion_criteria};\n",
    "    \"\"\"\n",
    "    cursor.execute(query_sql)\n",
    "    columns = [description[0] for description in cursor.description]\n",
    "    data = cursor.fetchall()\n",
    "    return pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(f\"PRAGMA table_info({TableNames.STATUS});\")\n",
    "status_columns = [row[1] for row in cursor.fetchall()]\n",
    "status_columns = [col for col in status_columns if col != primary_key]\n",
    "query_sql = f\"\"\"\n",
    "SELECT {primary_key}, {', '.join(status_columns)} \n",
    "FROM {TableNames.STATUS} s\n",
    "{exclusion_criteria};\n",
    "\"\"\"\n",
    "cursor.execute(query_sql)\n",
    "status_columns = [description[0] for description in cursor.description]\n",
    "status_data = cursor.fetchall()\n",
    "df_status = pd.DataFrame(status_data, columns=status_columns)\n",
    "df_status = df_status[['eid', 'event', 'time']]  # We only need these three columns for survival analysis\n",
    "\n",
    "df_covariates = retrieve_data(cursor, TableNames.COVARIATES)\n",
    "df_hrv_time = retrieve_data(cursor, TableNames.HRV_TIME)\n",
    "df_hrv_freq = retrieve_data(cursor, TableNames.HRV_FREQ)\n",
    "df_hrv_poincare = retrieve_data(cursor, TableNames.HRV_POINCARE)\n",
    "df_hrv_entropy = retrieve_data(cursor, TableNames.HRV_ENTROPY)\n",
    "df_hrv_fractal = retrieve_data(cursor, TableNames.HRV_FRACTAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status:  (35159, 3)\n",
      "Covariates:  (35159, 15)\n",
      "HRV Time:  (35159, 20)\n",
      "HRV Freq:  (35159, 9)\n",
      "HRV Poincare:  (35159, 28)\n",
      "HRV Entropy:  (35159, 8)\n",
      "HRV Fractal:  (35159, 23)\n"
     ]
    }
   ],
   "source": [
    "print(\"Status: \", df_status.shape)\n",
    "print(\"Covariates: \", df_covariates.shape)\n",
    "print(\"HRV Time: \", df_hrv_time.shape)\n",
    "print(\"HRV Freq: \", df_hrv_freq.shape)\n",
    "print(\"HRV Poincare: \", df_hrv_poincare.shape)\n",
    "print(\"HRV Entropy: \", df_hrv_entropy.shape)\n",
    "print(\"HRV Fractal: \", df_hrv_fractal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35159, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>event</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>BMI</th>\n",
       "      <th>smoking</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>...</th>\n",
       "      <th>HRV_MFDFA_alpha1_Fluctuation</th>\n",
       "      <th>HRV_MFDFA_alpha1_Increment</th>\n",
       "      <th>HRV_MFDFA_alpha2_Width</th>\n",
       "      <th>HRV_MFDFA_alpha2_Peak</th>\n",
       "      <th>HRV_MFDFA_alpha2_Mean</th>\n",
       "      <th>HRV_MFDFA_alpha2_Max</th>\n",
       "      <th>HRV_MFDFA_alpha2_Delta</th>\n",
       "      <th>HRV_MFDFA_alpha2_Asymmetry</th>\n",
       "      <th>HRV_MFDFA_alpha2_Fluctuation</th>\n",
       "      <th>HRV_MFDFA_alpha2_Increment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000205</td>\n",
       "      <td>0</td>\n",
       "      <td>4575</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.5595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.226993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000239</td>\n",
       "      <td>0</td>\n",
       "      <td>4638</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.9214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.127227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000677</td>\n",
       "      <td>0</td>\n",
       "      <td>4590</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.8920</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.104668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000737</td>\n",
       "      <td>0</td>\n",
       "      <td>4602</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.8374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.220395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000779</td>\n",
       "      <td>0</td>\n",
       "      <td>4514</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.394044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       eid  event  time  age  sex ethnicity      BMI  smoking  diabetes  \\\n",
       "0  1000205      0  4575   40    1         1  21.5595      0.0       0.0   \n",
       "1  1000239      0  4638   65    0         1  22.9214      1.0       0.0   \n",
       "2  1000677      0  4590   42    0         1  37.8920      2.0       0.0   \n",
       "3  1000737      0  4602   52    1         1  22.8374      0.0       0.0   \n",
       "4  1000779      0  4514   56    1         1  25.0194      0.0       0.0   \n",
       "\n",
       "   systolic_bp  ...  HRV_MFDFA_alpha1_Fluctuation  HRV_MFDFA_alpha1_Increment  \\\n",
       "0        149.0  ...                      0.003499                    0.226993   \n",
       "1        137.0  ...                      0.001239                    0.127227   \n",
       "2        124.0  ...                      0.001113                    0.104668   \n",
       "3        148.0  ...                      0.001417                    0.220395   \n",
       "4        144.0  ...                      0.003003                    0.394044   \n",
       "\n",
       "   HRV_MFDFA_alpha2_Width  HRV_MFDFA_alpha2_Peak  HRV_MFDFA_alpha2_Mean  \\\n",
       "0                     NaN                    NaN                    NaN   \n",
       "1                     NaN                    NaN                    NaN   \n",
       "2                     NaN                    NaN                    NaN   \n",
       "3                     NaN                    NaN                    NaN   \n",
       "4                     NaN                    NaN                    NaN   \n",
       "\n",
       "   HRV_MFDFA_alpha2_Max  HRV_MFDFA_alpha2_Delta  HRV_MFDFA_alpha2_Asymmetry  \\\n",
       "0                   NaN                     NaN                         NaN   \n",
       "1                   NaN                     NaN                         NaN   \n",
       "2                   NaN                     NaN                         NaN   \n",
       "3                   NaN                     NaN                         NaN   \n",
       "4                   NaN                     NaN                         NaN   \n",
       "\n",
       "   HRV_MFDFA_alpha2_Fluctuation  HRV_MFDFA_alpha2_Increment  \n",
       "0                           NaN                         NaN  \n",
       "1                           NaN                         NaN  \n",
       "2                           NaN                         NaN  \n",
       "3                           NaN                         NaN  \n",
       "4                           NaN                         NaN  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total = df_status.merge(\n",
    "    df_covariates, on='eid', how='inner'\n",
    ").merge(\n",
    "    df_hrv_time, on='eid', how='inner'\n",
    ").merge(\n",
    "    df_hrv_freq, on='eid', how='inner'\n",
    ").merge(\n",
    "    df_hrv_poincare, on='eid', how='inner'\n",
    ").merge(\n",
    "    df_hrv_entropy, on='eid', how='inner'\n",
    ").merge(\n",
    "    df_hrv_fractal, on='eid', how='inner'\n",
    ")\n",
    "print(df_total.shape)\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv(\"total_data_unimputed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "\n",
    "Now we split the data to training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df_total, \n",
    "    test_size=0.2, \n",
    "    random_state=1234,\n",
    "    stratify=df_total['event']  # Make sure both data have the same proportion of event\n",
    ")\n",
    "df_train.to_csv(\"train_data_unimputed.csv\")\n",
    "df_test.to_csv(\"test_data_unimputed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
